{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c63032-a8e6-49e3-aca8-6b15e2e36cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fft2, fftshift\n",
    "import csv \n",
    "def radial_profile(data):\n",
    "    \"\"\"Computes the radial profile of a 2D FFT result.\"\"\"\n",
    "    y, x = np.indices((data.shape))\n",
    "    center = np.array([y.max() // 2, x.max() // 2])  # Find the center of the FFT image\n",
    "    \n",
    "    r = np.sqrt((x - center[1]) ** 2 + (y - center[0]) ** 2)  # Radial distance from the center\n",
    "    r = r.astype(int)  # Round distances to integers\n",
    "    \n",
    "    # Compute the mean value for all points at the same radial distance\n",
    "    radial_mean = np.bincount(r.ravel(), data.ravel()) / np.bincount(r.ravel())\n",
    "    \n",
    "    return radial_mean\n",
    "\n",
    "def compute_fft_spectrum(img, low_freq_cutoff):\n",
    "    \"\"\"Computes the 2D FFT and radial mean profile of the image, with low frequencies removed.\"\"\"\n",
    "    # Perform FFT\n",
    "    fft = np.fft.fft2(img)\n",
    "    fft_shifted = np.fft.fftshift(fft)\n",
    "    \n",
    "    # Compute the magnitude spectrum\n",
    "    magnitude_spectrum = np.abs(fft_shifted)\n",
    "    \n",
    "    # Remove low-frequency bins (around the center)\n",
    "    center = (magnitude_spectrum.shape[0] // 2, magnitude_spectrum.shape[1] // 2)\n",
    "    magnitude_spectrum[center[0] - low_freq_cutoff:center[0] + low_freq_cutoff, center[1] - low_freq_cutoff:center[1] + low_freq_cutoff] = 0\n",
    "    \n",
    "    # Compute radial profile (amplitude as a function of frequency)\n",
    "    radial_mean = radial_profile(magnitude_spectrum)\n",
    "    \n",
    "    return magnitude_spectrum, radial_mean\n",
    "\n",
    "\n",
    "def plot_fft_and_radial(spectrum, radial_mean, crop_index):\n",
    "    \"\"\"Plots both the 2D FFT magnitude spectrum and the radial profile.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot 2D FFT magnitude spectrum\n",
    "    ax1.imshow(np.log(1 + spectrum), cmap='gray')\n",
    "    ax1.set_title(f'2D FFT Magnitude Spectrum (Crop {crop_index + 1})')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot radial mean profile\n",
    "    ax2.plot(radial_mean, label=f'Crop {crop_index + 1}')\n",
    "    ax2.set_title('Amplitude-Versus-Frequency Spectrum')\n",
    "    ax2.set_xlabel('Frequency (Radial Distance)')\n",
    "    ax2.set_ylabel('Amplitude (Mean Magnitude)')\n",
    "    plt.savefig(f\"spectrum_rgb_{crop_index}_BC15-01.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_spectra_for_crops(cropped_imgs,lowfrequency_cutoff):\n",
    "    \"\"\"Computes the amplitude-versus-frequency spectra for all cropped images.\"\"\"\n",
    "    radial_profiles=[]\n",
    "    for idx, img in enumerate(cropped_imgs):\n",
    "        if len(img.shape) == 3:  # For RGB images\n",
    "            # Convert to grayscale by averaging the color channels\n",
    "            img_gray = np.mean(img, axis=2)\n",
    "        else:\n",
    "            img_gray = img  # For grayscale or single-channel images\n",
    "            \n",
    "        # Compute the FFT spectrum and radial mean\n",
    "        magnitude_spectrum, radial_mean = compute_fft_spectrum(img_gray,lowfrequency_cutoff)\n",
    "        radial_profiles.append(radial_mean)\n",
    "        # Plot both 2D FFT and radial profile\n",
    "        plot_fft_and_radial(magnitude_spectrum, radial_mean, idx)\n",
    "    return radial_profiles\n",
    "\n",
    "def truncate_profiles_to_min_length(radial_profiles):\n",
    "    \"\"\"Truncates all radial profiles to the minimum length found in the data.\"\"\"\n",
    "    min_length = min([len(profile) for profile in radial_profiles])  # Find the minimum length\n",
    "    truncated_profiles = [profile[:min_length] for profile in radial_profiles]  # Truncate each profile\n",
    "    return np.array(truncated_profiles)\n",
    "\n",
    "def compute_mean_and_std(radial_profiles):\n",
    "    \"\"\"Computes the mean and standard deviation of the truncated radial profiles for all images.\"\"\"\n",
    "    # Truncate the profiles to the minimum length\n",
    "    truncated_profiles = truncate_profiles_to_min_length(radial_profiles)\n",
    "    \n",
    "    # Compute the mean and standard deviation across the images for each frequency\n",
    "    mean_amplitude = np.mean(truncated_profiles, axis=0)\n",
    "    std_amplitude = np.std(truncated_profiles, axis=0)\n",
    "    \n",
    "    return mean_amplitude, std_amplitude\n",
    "\n",
    "def plot_mean_and_std(mean_amplitude, std_amplitude=None):\n",
    "    \"\"\"Plot the mean amplitude with optional standard deviation curves.\"\"\"\n",
    "    frequencies = np.arange(len(mean_amplitude))  # Frequency axis (indices)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot mean amplitude\n",
    "    plt.plot(frequencies, mean_amplitude, label='Mean Amplitude', color='blue')\n",
    "    \n",
    "    # Optionally, plot mean Â± std curves\n",
    "    if std_amplitude is not None:\n",
    "        plt.plot(frequencies, mean_amplitude + std_amplitude, '--', color='green', label='Mean + Std')\n",
    "        plt.plot(frequencies, mean_amplitude - std_amplitude, '--', color='red', label='Mean - Std')\n",
    "    \n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Mean Amplitude Spectrum (with Std. Deviation)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def compute_pixel_boundaries(img):\n",
    "    \"\"\"Get the maximum boundary value for the image's data type.\"\"\"\n",
    "    dtype = img.dtype\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        return np.iinfo(dtype).max  # Max value for integer types\n",
    "    elif np.issubdtype(dtype, np.floating):\n",
    "        return 1.0  # Assume normalized floating-point values are between 0 and 1\n",
    "    return 1  # Default to 1 if unknown\n",
    "\n",
    "def normalize_values(values, img):\n",
    "    \"\"\"Normalize the values based on the image dtype.\"\"\"\n",
    "    boundary = compute_pixel_boundaries(img)\n",
    "    return values / boundary\n",
    "\n",
    "def save_max_mean_and_std_csv(species, max_mean, max_std, file_path='Spectrum_all.csv'):\n",
    "    \"\"\"Save the max mean and std for the given species in a CSV file.\"\"\"\n",
    "    # Open the CSV file in append mode\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    \n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header if the file is newly created\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Species', 'Max Mean', 'Max Std'])\n",
    "        \n",
    "        # Write the species, max_mean, and max_std to the CSV\n",
    "        writer.writerow([species, max_mean, max_std])\n",
    "    \n",
    "    print(f\"Max mean and std saved for {species} in {file_path}\")\n",
    "\n",
    "Species=species+'_rgb'\n",
    "# Assume radial profiles have already been computed\n",
    "# Compute radial profiles for all RGB and HSI cropped images\n",
    "radial_profiles_rgb = compute_spectra_for_crops(croped_rgb,5)\n",
    "\n",
    "# Compute the mean and standard deviation for RGB\n",
    "mean_rgb, std_rgb = compute_mean_and_std(radial_profiles_rgb)\n",
    "\n",
    "# Normalize the mean and std based on the dtype of the image\n",
    "normalized_mean = normalize_values(mean_rgb, croped_rgb[0])\n",
    "normalized_std = normalize_values(std_rgb, croped_rgb[0])\n",
    "\n",
    "# Save the max mean and max std values for the species in a CSV file\n",
    "max_mean_rgb = np.max(normalized_mean)\n",
    "max_std_rgb = np.max(normalized_std)\n",
    "save_max_mean_and_std_csv(Species, max_mean_rgb, max_std_rgb)\n",
    "\n",
    "# Plot the normalized results\n",
    "plot_mean_and_std(normalized_mean, std_amplitude=normalized_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3499b-e189-4d59-b32f-7b048694e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fft2, fftshift\n",
    "import csv \n",
    "def radial_profile(data):\n",
    "    \"\"\"Computes the radial profile of a 2D FFT result.\"\"\"\n",
    "    y, x = np.indices((data.shape))\n",
    "    center = np.array([y.max() // 2, x.max() // 2])  # Find the center of the FFT image\n",
    "    \n",
    "    r = np.sqrt((x - center[1]) ** 2 + (y - center[0]) ** 2)  # Radial distance from the center\n",
    "    r = r.astype(int)  # Round distances to integers\n",
    "    \n",
    "    # Compute the mean value for all points at the same radial distance\n",
    "    radial_mean = np.bincount(r.ravel(), data.ravel()) / np.bincount(r.ravel())\n",
    "    \n",
    "    return radial_mean\n",
    "\n",
    "def compute_fft_spectrum(img, low_freq_cutoff):\n",
    "    \"\"\"Computes the 2D FFT and radial mean profile of the image, with low frequencies removed.\"\"\"\n",
    "    # Perform FFT\n",
    "    fft = np.fft.fft2(img)\n",
    "    fft_shifted = np.fft.fftshift(fft)\n",
    "    \n",
    "    # Compute the magnitude spectrum\n",
    "    magnitude_spectrum = np.abs(fft_shifted)\n",
    "    \n",
    "    # Remove low-frequency bins (around the center)\n",
    "    center = (magnitude_spectrum.shape[0] // 2, magnitude_spectrum.shape[1] // 2)\n",
    "    magnitude_spectrum[center[0] - low_freq_cutoff:center[0] + low_freq_cutoff, center[1] - low_freq_cutoff:center[1] + low_freq_cutoff] = 0\n",
    "    \n",
    "    # Compute radial profile (amplitude as a function of frequency)\n",
    "    radial_mean = radial_profile(magnitude_spectrum)\n",
    "    \n",
    "    return magnitude_spectrum, radial_mean\n",
    "\n",
    "\n",
    "def plot_fft_and_radial(spectrum, radial_mean, crop_index):\n",
    "    \"\"\"Plots both the 2D FFT magnitude spectrum and the radial profile.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot 2D FFT magnitude spectrum\n",
    "    ax1.imshow(np.log(1 + spectrum), cmap='gray')\n",
    "    ax1.set_title(f'2D FFT Magnitude Spectrum (Crop {crop_index + 1})')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot radial mean profile\n",
    "    ax2.plot(radial_mean, label=f'Crop {crop_index + 1}')\n",
    "    ax2.set_title('Amplitude-Versus-Frequency Spectrum')\n",
    "    ax2.set_xlabel('Frequency (Radial Distance)')\n",
    "    ax2.set_ylabel('Amplitude (Mean Magnitude)')\n",
    "    plt.savefig(f\"spectrum_rgb_{crop_index}_BC15-01.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_spectra_for_crops(cropped_imgs,lowfrequency_cutoff):\n",
    "    \"\"\"Computes the amplitude-versus-frequency spectra for all cropped images.\"\"\"\n",
    "    radial_profiles=[]\n",
    "    for idx, img in enumerate(cropped_imgs):\n",
    "        if len(img.shape) == 3:  # For RGB images\n",
    "            # Convert to grayscale by averaging the color channels\n",
    "            img_gray = np.mean(img, axis=2)\n",
    "        else:\n",
    "            img_gray = img  # For grayscale or single-channel images\n",
    "            \n",
    "        # Compute the FFT spectrum and radial mean\n",
    "        magnitude_spectrum, radial_mean = compute_fft_spectrum(img_gray,lowfrequency_cutoff)\n",
    "        radial_profiles.append(radial_mean)\n",
    "        # Plot both 2D FFT and radial profile\n",
    "        plot_fft_and_radial(magnitude_spectrum, radial_mean, idx)\n",
    "    return radial_profiles\n",
    "\n",
    "def truncate_profiles_to_min_length(radial_profiles):\n",
    "    \"\"\"Truncates all radial profiles to the minimum length found in the data.\"\"\"\n",
    "    min_length = min([len(profile) for profile in radial_profiles])  # Find the minimum length\n",
    "    truncated_profiles = [profile[:min_length] for profile in radial_profiles]  # Truncate each profile\n",
    "    return np.array(truncated_profiles)\n",
    "\n",
    "def compute_mean_and_std(radial_profiles):\n",
    "    \"\"\"Computes the mean and standard deviation of the truncated radial profiles for all images.\"\"\"\n",
    "    # Truncate the profiles to the minimum length\n",
    "    truncated_profiles = truncate_profiles_to_min_length(radial_profiles)\n",
    "    \n",
    "    # Compute the mean and standard deviation across the images for each frequency\n",
    "    mean_amplitude = np.mean(truncated_profiles, axis=0)\n",
    "    std_amplitude = np.std(truncated_profiles, axis=0)\n",
    "    \n",
    "    return mean_amplitude, std_amplitude\n",
    "\n",
    "def plot_mean_and_std(mean_amplitude, std_amplitude=None):\n",
    "    \"\"\"Plot the mean amplitude with optional standard deviation curves.\"\"\"\n",
    "    frequencies = np.arange(len(mean_amplitude))  # Frequency axis (indices)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot mean amplitude\n",
    "    plt.plot(frequencies, mean_amplitude, label='Mean Amplitude', color='blue')\n",
    "    \n",
    "    # Optionally, plot mean Â± std curves\n",
    "    if std_amplitude is not None:\n",
    "        plt.plot(frequencies, mean_amplitude + std_amplitude, '--', color='green', label='Mean + Std')\n",
    "        plt.plot(frequencies, mean_amplitude - std_amplitude, '--', color='red', label='Mean - Std')\n",
    "    \n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Mean Amplitude Spectrum (with Std. Deviation)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def compute_pixel_boundaries(img):\n",
    "    \"\"\"Get the maximum boundary value for the image's data type.\"\"\"\n",
    "    dtype = img.dtype\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        return np.iinfo(dtype).max  # Max value for integer types\n",
    "    elif np.issubdtype(dtype, np.floating):\n",
    "        return 1.0  # Assume normalized floating-point values are between 0 and 1\n",
    "    return 1  # Default to 1 if unknown\n",
    "\n",
    "def normalize_values(values, img):\n",
    "    \"\"\"Normalize the values based on the image dtype.\"\"\"\n",
    "    boundary = compute_pixel_boundaries(img)\n",
    "    return values / boundary\n",
    "\n",
    "def save_max_mean_and_std_csv(species, max_mean, max_std, file_path='Spectrum_all.csv'):\n",
    "    \"\"\"Save the max mean and std for the given species in a CSV file.\"\"\"\n",
    "    # Open the CSV file in append mode\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    \n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header if the file is newly created\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Species', 'Max Mean', 'Max Std'])\n",
    "        \n",
    "        # Write the species, max_mean, and max_std to the CSV\n",
    "        writer.writerow([species, max_mean, max_std])\n",
    "    \n",
    "    print(f\"Max mean and std saved for {species} in {file_path}\")\n",
    "    \n",
    "Species=species+'_reconstruct'\n",
    "# Assume radial profiles have already been computed\n",
    "# Compute radial profiles for all RGB and HSI cropped images\n",
    "radial_profiles_rgb = compute_spectra_for_crops(croped_reconstruct,5)\n",
    "\n",
    "# Compute the mean and standard deviation for RGB\n",
    "mean_rgb, std_rgb = compute_mean_and_std(radial_profiles_rgb)\n",
    "\n",
    "# Normalize the mean and std based on the dtype of the image\n",
    "normalized_mean = normalize_values(mean_rgb, croped_rgb[0])\n",
    "normalized_std = normalize_values(std_rgb, croped_rgb[0])\n",
    "\n",
    "# Save the max mean and max std values for the species in a CSV file\n",
    "max_mean_rgb = np.max(normalized_mean)\n",
    "max_std_rgb = np.max(normalized_std)\n",
    "save_max_mean_and_std_csv(Species, max_mean_rgb, max_std_rgb)\n",
    "\n",
    "# Plot the normalized results\n",
    "plot_mean_and_std(normalized_mean, std_amplitude=normalized_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3f0a5-8328-4388-a6a2-2467555574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Species=species+'_hsi'\n",
    "# Assume radial profiles have already been computed\n",
    "# Compute radial profiles for all RGB and HSI cropped images\n",
    "radial_profiles_rgb = compute_spectra_for_crops(croped_hsi,1)\n",
    "\n",
    "# Compute the mean and standard deviation for RGB\n",
    "mean_rgb, std_rgb = compute_mean_and_std(radial_profiles_rgb)\n",
    "\n",
    "# Normalize the mean and std based on the dtype of the image\n",
    "normalized_mean = normalize_values(mean_rgb, croped_rgb[0])\n",
    "normalized_std = normalize_values(std_rgb, croped_rgb[0])\n",
    "\n",
    "# Save the max mean and max std values for the species in a CSV file\n",
    "max_mean_rgb = np.max(normalized_mean)\n",
    "max_std_rgb = np.max(normalized_std)\n",
    "save_max_mean_and_std_csv(Species, max_mean_rgb, max_std_rgb)\n",
    "\n",
    "# Plot the normalized results\n",
    "plot_mean_and_std(normalized_mean, std_amplitude=normalized_std)\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e20932-1025-479a-ac68-2c37002de940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyefd import elliptic_fourier_descriptors, normalize_efd, reconstruct_contour\n",
    "import csv \n",
    "\n",
    "def canny_edge_detection(img):\n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    return edges\n",
    "\n",
    "# Apply Canny edge detection to each crop\n",
    "def apply_canny_to_crops(cropped_images):\n",
    "    canny_crops = []\n",
    "    for i, img in enumerate(cropped_images):\n",
    "        # Convert image to grayscale if it's in color\n",
    "        img_gray = np.mean(img,axis=2).astype(img.dtype) # For grayscale or single-channel images\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = canny_edge_detection(img_gray)\n",
    "        \n",
    "        # Append the edges to the list\n",
    "        canny_crops.append(edges)\n",
    "\n",
    "    return canny_crops\n",
    "\n",
    "\n",
    "def extract_contours(edge_image):\n",
    "    \"\"\"Extract contours from the edge-detected image.\"\"\"\n",
    "    contours, _ = cv2.findContours(edge_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def compute_efd(contours, order=10):\n",
    "    \"\"\"Compute the Elliptic Fourier Descriptors for each contour.\"\"\"\n",
    "    efd_coeffs = []\n",
    "    for contour in contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        if len(contour) > 10:  # Ensure contour has enough points\n",
    "            coeffs = elliptic_fourier_descriptors(contour, order=order, normalize=False)\n",
    "            efd_coeffs.append(coeffs)\n",
    "    return efd_coeffs\n",
    "\n",
    "def rescale_contour(contour, original_image_shape):\n",
    "    \"\"\"Rescale the reconstructed contour to the original image dimensions.\"\"\"\n",
    "    height, width = original_image_shape[:2]\n",
    "    \n",
    "    # Normalize contour between 0 and 1 (as EFD often works with normalized coordinates)\n",
    "    contour_min = np.min(contour, axis=0)\n",
    "    contour_max = np.max(contour, axis=0)\n",
    "    \n",
    "    normalized_contour = (contour - contour_min) / (contour_max - contour_min)\n",
    "    \n",
    "    # Scale the normalized contour to the size of the original image\n",
    "    rescaled_contour = np.zeros_like(normalized_contour)\n",
    "    rescaled_contour[:, 0] = normalized_contour[:, 0] * width  # Scale x coordinates\n",
    "    rescaled_contour[:, 1] = normalized_contour[:, 1] * height  # Scale y coordinates\n",
    "    \n",
    "    return rescaled_contour\n",
    "\n",
    "def reconstruct_shape(coeffs, original_image_shape):\n",
    "    \"\"\"Reconstruct the shape from normalized EFD coefficients.\"\"\"\n",
    "    # Normalize EFD coefficients\n",
    "    coeffs = normalize_efd(coeffs)\n",
    "    # Reconstruct contour from normalized EFD\n",
    "    reconstructed_contour = reconstruct_contour(coeffs, locus=(0, 0), num_points=500)\n",
    "    \n",
    "    # Rescale the reconstructed contour to the original image dimensions\n",
    "    rescaled_contour = rescale_contour(reconstructed_contour, original_image_shape)\n",
    "    \n",
    "    return rescaled_contour\n",
    "\n",
    "def plot_contours(original_img, original_contours, reconstructed_contours, contour_features, image_index):\n",
    "    \"\"\"Plot the original contours and the reconstructed ones side by side, \n",
    "    with morphological features marked on the reconstructed contours.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot original contours\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    for contour in original_contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        plt.plot(contour[:, 0], contour[:, 1], color='blue')\n",
    "    plt.title(\"Original Contours\")\n",
    "\n",
    "    # Plot reconstructed contours with features\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.ones((200,60)) * 255, cmap='gray')  # White background\n",
    "    \n",
    "    for idx, (contour, features) in enumerate(zip(reconstructed_contours, contour_features)):\n",
    "        plt.plot(contour[:, 0], contour[:, 1], color='red')\n",
    "        \n",
    "        # Calculate the center of the contour\n",
    "        center_x = np.mean(contour[:, 0])\n",
    "        center_y = np.mean(contour[:, 1])\n",
    "        \n",
    "        # Mark major and minor axis lengths\n",
    "        plt.text(center_x, center_y, f\"f2: {features['f2']:.2f}\\nf3: {features['f3']:.2f}\", \n",
    "                ha='center', va='center', fontsize=8, color='green')\n",
    "        \n",
    "    plt.title(\"Reconstructed Contours from EFD\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_morphological_features(contour):\n",
    "    \"\"\"Compute morphological features of the given contour.\"\"\"\n",
    "    if len(contour.shape) == 2:\n",
    "        contour = np.expand_dims(contour, axis=1)\n",
    "    contour = np.array(contour, dtype=np.float32)\n",
    "    features = {}\n",
    "\n",
    "    # Feature f1: Area (number of pixels inside the contour)\n",
    "    f1_area = cv2.contourArea(contour)\n",
    "    \n",
    "    # Feature f5: Perimeter (number of pixels along the boundary)\n",
    "    f5_perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Check if the contour has enough points to fit an ellipse\n",
    "    if len(contour) >= 5:\n",
    "        # Fit an ellipse to the contour\n",
    "        ellipse = cv2.fitEllipse(contour)\n",
    "        \n",
    "        # Get major and minor axis lengths (f2 and f3)\n",
    "        (center, (major_axis_length, minor_axis_length), angle) = ellipse\n",
    "        \n",
    "        f2_major_axis_length = max(major_axis_length, minor_axis_length)  # Major axis\n",
    "        f3_minor_axis_length = min(major_axis_length, minor_axis_length)  # Minor axis\n",
    "        \n",
    "        # Feature f4: MinorAxisLength / MajorAxisLength\n",
    "        f4_axis_ratio = f3_minor_axis_length / f2_major_axis_length\n",
    "        \n",
    "        # Feature f6: FociDistance / MajorAxisLength (Eccentricity)\n",
    "        foci_distance = np.sqrt(f2_major_axis_length**2 - f3_minor_axis_length**2)\n",
    "        f6_eccentricity = foci_distance / f2_major_axis_length\n",
    "    else:\n",
    "        # If there are not enough points to fit an ellipse, set features to zero or NaN\n",
    "        f2_major_axis_length = f3_minor_axis_length = f4_axis_ratio = f6_eccentricity = np.nan\n",
    "    \n",
    "    # Feature f5: Perimeter / Area\n",
    "    f5_perimeter_area_ratio = f5_perimeter / f1_area if f1_area != 0 else np.nan\n",
    "    \n",
    "    # Store features in a dictionary\n",
    "    features['f1'] = f1_area\n",
    "    features['f2'] = f2_major_axis_length\n",
    "    features['f3'] = f3_minor_axis_length\n",
    "    features['f4'] = f4_axis_ratio\n",
    "    features['f5'] = f5_perimeter_area_ratio\n",
    "    features['f6'] = f6_eccentricity\n",
    "    \n",
    "    return features\n",
    "def apply_closing(canny_image, kernel_size=(3, 3)):\n",
    "    \"\"\"\n",
    "    Apply morphological closing on the given image.\n",
    "    \n",
    "    Parameters:\n",
    "    canny_image (np.ndarray): The input edge-detected image (e.g., from Canny edge detection).\n",
    "    kernel_size (tuple): The size of the structuring element (kernel) used for closing.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image after applying morphological closing.\n",
    "    \"\"\"\n",
    "    image=canny_image\n",
    "    for i in range(5):\n",
    "        # Create a structuring element (kernel) for closing\n",
    "        kernel = np.ones(kernel_size, np.uint8)\n",
    "        \n",
    "        # Apply morphological closing (dilation followed by erosion)\n",
    "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    closed_image = image\n",
    "    return closed_image\n",
    "def compute_features_for_contours(contours):\n",
    "    \"\"\"Compute morphological features for each contour.\"\"\"\n",
    "    all_features = []\n",
    "    for contour in contours:\n",
    "        features = compute_morphological_features(contour)\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "def remove_small_contours(image, min_area=80):\n",
    "    \"\"\"\n",
    "    Remove small contours from the image based on a minimum area threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): The input binary image (typically an edge-detected or thresholded image).\n",
    "    min_area (int): The minimum area threshold for keeping contours. Contours with area smaller than this will be removed.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image with small contours removed.\n",
    "    \"\"\"\n",
    "    # Find all contours in the image\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create an empty mask to draw the filtered contours\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    # Loop over each contour\n",
    "    for contour in contours:\n",
    "        # Calculate the contour area\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # If the contour area is larger than the minimum area, draw it on the mask\n",
    "        if area >= min_area:\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)  # Fill the contour\n",
    "    \n",
    "    return mask\n",
    "def draw_contours_on_image(image, contours):\n",
    "    \"\"\"\n",
    "    Draw contours on the original image and display them.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The original image or edge-detected image (e.g., Canny image).\n",
    "    contours (list): List of contours to draw on the image.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the image with contours using matplotlib.\n",
    "    \"\"\"\n",
    "    # Create a copy of the original image to draw on\n",
    "    image_with_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert grayscale image to BGR for colored contours\n",
    "    \n",
    "    # Draw the contours on the image (green color with thickness of 2)\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the result using matplotlib\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(image_with_contours, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display in matplotlib\n",
    "    plt.title('Contours Overlayed on the Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def clean_image(canny_image):\n",
    "    # Step 1: Apply morphological closing with a kernel size of (1, 1)\n",
    "    closed_canny_image = apply_closing(canny_image, kernel_size=(3, 3))\n",
    "    # Step 2: Remove small contours based on area\n",
    "    cleaned_canny_image = remove_small_contours(closed_canny_image, min_area=80)\n",
    "    return cleaned_canny_image\n",
    "def compute_mean_and_std_for_all_crops(all_features):\n",
    "    \"\"\"Compute the mean and std for each feature (f1 to f6) across all crops.\"\"\"\n",
    "    features_array = {f'f{i}': [] for i in range(1, 7)}\n",
    "    \n",
    "    for features in all_features:\n",
    "        for key in features_array.keys():\n",
    "            features_array[key].append(features[key])\n",
    "\n",
    "    mean_features = {key: np.nanmean(values) for key, values in features_array.items()}\n",
    "    std_features = {key: np.nanstd(values) for key, values in features_array.items()}\n",
    "\n",
    "    return mean_features, std_features\n",
    "def save_mean_std_to_csv(species, mean_features, std_features, file_path='Morphological_all.csv'):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Species', 'Mean_f1', 'Mean_f2', 'Mean_f3', 'Mean_f4', 'Mean_f5', 'Mean_f6',\n",
    "                             'Std_f1', 'Std_f2', 'Std_f3', 'Std_f4', 'Std_f5', 'Std_f6'])\n",
    "        \n",
    "        mean_row = [mean_features[f'f{i}'] for i in range(1, 7)]\n",
    "        std_row = [std_features[f'f{i}'] for i in range(1, 7)]\n",
    "        \n",
    "        writer.writerow([species] + mean_row + std_row)\n",
    "        \n",
    "def is_closed_contour(contour, tolerance=3):\n",
    "    \"\"\"Check if the contour is 'closed' by comparing the start and end points.\"\"\"\n",
    "    start_point = contour[0]\n",
    "    end_point = contour[-1]\n",
    "    distance = np.linalg.norm(start_point - end_point)\n",
    "    return distance < tolerance\n",
    "    \n",
    "Species=species+'_rgb'\n",
    "# Apply Canny edge detection to RGB and HSI crops\n",
    "canny_rgb_crops = apply_canny_to_crops(croped_rgb)\n",
    "all_contour_features = []\n",
    "for i in range(48):\n",
    "    # Assuming canny_rgb_crops[6] contains your edge-detected image\n",
    "    canny_image = clean_image(canny_rgb_crops[i])\n",
    "    \n",
    "    # Step 1: Extract contours from the edge-detected image\n",
    "    contours = extract_contours(canny_image)\n",
    "    # Filter contours that are not closed\n",
    "    closed_contours = [contour for contour in contours if is_closed_contour(contour)]\n",
    "    \n",
    "    if not closed_contours:\n",
    "        continue\n",
    "    \n",
    "    # Visualize contours on the Canny image to check if they are correct\n",
    "    draw_contours_on_image(canny_image, contours)\n",
    "    \n",
    "    # Step 2: Compute EFD coefficients for each contour\n",
    "    efd_coeffs = compute_efd(contours)\n",
    "    \n",
    "    # Step 3: Reconstruct the shape using normalized EFD and rescale it to original image size\n",
    "    reconstructed_contours = [reconstruct_shape(coeffs, (200, 60)) for coeffs in efd_coeffs]\n",
    "    # Assuming reconstructed_contours contains the reconstructed contours\n",
    "    contour_features = compute_features_for_contours(reconstructed_contours)\n",
    "    all_contour_features.extend(contour_features)\n",
    "    # Display the computed features for each contour    \n",
    "    # Step 4: Plot original and reconstructed contours\n",
    "    print(i)\n",
    "    plot_contours(canny_image, contours, reconstructed_contours, contour_features,i)\n",
    "\n",
    "# Compute mean and standard deviation of features across all crops\n",
    "mean_features, std_features = compute_mean_and_std_for_all_crops(all_contour_features)\n",
    "# Save mean and std features to CSV\n",
    "save_mean_std_to_csv(Species, mean_features, std_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660f751-0e5d-4fec-a749-9bb43e21ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyefd import elliptic_fourier_descriptors, normalize_efd, reconstruct_contour\n",
    "import csv \n",
    "\n",
    "def canny_edge_detection(img):\n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    return edges\n",
    "\n",
    "# Apply Canny edge detection to each crop\n",
    "def apply_canny_to_crops(cropped_images):\n",
    "    canny_crops = []\n",
    "    for i, img in enumerate(cropped_images):\n",
    "        # Convert image to grayscale if it's in color\n",
    "        img_gray = np.mean(img,axis=2).astype(img.dtype) # For grayscale or single-channel images\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = canny_edge_detection(img_gray)\n",
    "        \n",
    "        # Append the edges to the list\n",
    "        canny_crops.append(edges)\n",
    "\n",
    "    return canny_crops\n",
    "\n",
    "\n",
    "def extract_contours(edge_image):\n",
    "    \"\"\"Extract contours from the edge-detected image.\"\"\"\n",
    "    contours, _ = cv2.findContours(edge_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def compute_efd(contours, order=10):\n",
    "    \"\"\"Compute the Elliptic Fourier Descriptors for each contour.\"\"\"\n",
    "    efd_coeffs = []\n",
    "    for contour in contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        if len(contour) > 10:  # Ensure contour has enough points\n",
    "            coeffs = elliptic_fourier_descriptors(contour, order=order, normalize=False)\n",
    "            efd_coeffs.append(coeffs)\n",
    "    return efd_coeffs\n",
    "\n",
    "def rescale_contour(contour, original_image_shape):\n",
    "    \"\"\"Rescale the reconstructed contour to the original image dimensions.\"\"\"\n",
    "    height, width = original_image_shape[:2]\n",
    "    \n",
    "    # Normalize contour between 0 and 1 (as EFD often works with normalized coordinates)\n",
    "    contour_min = np.min(contour, axis=0)\n",
    "    contour_max = np.max(contour, axis=0)\n",
    "    \n",
    "    normalized_contour = (contour - contour_min) / (contour_max - contour_min)\n",
    "    \n",
    "    # Scale the normalized contour to the size of the original image\n",
    "    rescaled_contour = np.zeros_like(normalized_contour)\n",
    "    rescaled_contour[:, 0] = normalized_contour[:, 0] * width  # Scale x coordinates\n",
    "    rescaled_contour[:, 1] = normalized_contour[:, 1] * height  # Scale y coordinates\n",
    "    \n",
    "    return rescaled_contour\n",
    "\n",
    "def reconstruct_shape(coeffs, original_image_shape):\n",
    "    \"\"\"Reconstruct the shape from normalized EFD coefficients.\"\"\"\n",
    "    # Normalize EFD coefficients\n",
    "    coeffs = normalize_efd(coeffs)\n",
    "    # Reconstruct contour from normalized EFD\n",
    "    reconstructed_contour = reconstruct_contour(coeffs, locus=(0, 0), num_points=500)\n",
    "    \n",
    "    # Rescale the reconstructed contour to the original image dimensions\n",
    "    rescaled_contour = rescale_contour(reconstructed_contour, original_image_shape)\n",
    "    \n",
    "    return rescaled_contour\n",
    "\n",
    "def plot_contours(original_img, original_contours, reconstructed_contours, contour_features, image_index):\n",
    "    \"\"\"Plot the original contours and the reconstructed ones side by side, \n",
    "    with morphological features marked on the reconstructed contours.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot original contours\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    for contour in original_contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        plt.plot(contour[:, 0], contour[:, 1], color='blue')\n",
    "    plt.title(\"Original Contours\")\n",
    "\n",
    "    # Plot reconstructed contours with features\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.ones((200,60)) * 255, cmap='gray')  # White background\n",
    "    \n",
    "    for idx, (contour, features) in enumerate(zip(reconstructed_contours, contour_features)):\n",
    "        plt.plot(contour[:, 0], contour[:, 1], color='red')\n",
    "        \n",
    "        # Calculate the center of the contour\n",
    "        center_x = np.mean(contour[:, 0])\n",
    "        center_y = np.mean(contour[:, 1])\n",
    "        \n",
    "        # Mark major and minor axis lengths\n",
    "        plt.text(center_x, center_y, f\"f2: {features['f2']:.2f}\\nf3: {features['f3']:.2f}\", \n",
    "                ha='center', va='center', fontsize=8, color='green')\n",
    "        \n",
    "    plt.title(\"Reconstructed Contours from EFD\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_morphological_features(contour):\n",
    "    \"\"\"Compute morphological features of the given contour.\"\"\"\n",
    "    if len(contour.shape) == 2:\n",
    "        contour = np.expand_dims(contour, axis=1)\n",
    "    contour = np.array(contour, dtype=np.float32)\n",
    "    features = {}\n",
    "\n",
    "    # Feature f1: Area (number of pixels inside the contour)\n",
    "    f1_area = cv2.contourArea(contour)\n",
    "    \n",
    "    # Feature f5: Perimeter (number of pixels along the boundary)\n",
    "    f5_perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Check if the contour has enough points to fit an ellipse\n",
    "    if len(contour) >= 5:\n",
    "        # Fit an ellipse to the contour\n",
    "        ellipse = cv2.fitEllipse(contour)\n",
    "        \n",
    "        # Get major and minor axis lengths (f2 and f3)\n",
    "        (center, (major_axis_length, minor_axis_length), angle) = ellipse\n",
    "        \n",
    "        f2_major_axis_length = max(major_axis_length, minor_axis_length)  # Major axis\n",
    "        f3_minor_axis_length = min(major_axis_length, minor_axis_length)  # Minor axis\n",
    "        \n",
    "        # Feature f4: MinorAxisLength / MajorAxisLength\n",
    "        f4_axis_ratio = f3_minor_axis_length / f2_major_axis_length\n",
    "        \n",
    "        # Feature f6: FociDistance / MajorAxisLength (Eccentricity)\n",
    "        foci_distance = np.sqrt(f2_major_axis_length**2 - f3_minor_axis_length**2)\n",
    "        f6_eccentricity = foci_distance / f2_major_axis_length\n",
    "    else:\n",
    "        # If there are not enough points to fit an ellipse, set features to zero or NaN\n",
    "        f2_major_axis_length = f3_minor_axis_length = f4_axis_ratio = f6_eccentricity = np.nan\n",
    "    \n",
    "    # Feature f5: Perimeter / Area\n",
    "    f5_perimeter_area_ratio = f5_perimeter / f1_area if f1_area != 0 else np.nan\n",
    "    \n",
    "    # Store features in a dictionary\n",
    "    features['f1'] = f1_area\n",
    "    features['f2'] = f2_major_axis_length\n",
    "    features['f3'] = f3_minor_axis_length\n",
    "    features['f4'] = f4_axis_ratio\n",
    "    features['f5'] = f5_perimeter_area_ratio\n",
    "    features['f6'] = f6_eccentricity\n",
    "    \n",
    "    return features\n",
    "def apply_closing(canny_image, kernel_size=(3, 3)):\n",
    "    \"\"\"\n",
    "    Apply morphological closing on the given image.\n",
    "    \n",
    "    Parameters:\n",
    "    canny_image (np.ndarray): The input edge-detected image (e.g., from Canny edge detection).\n",
    "    kernel_size (tuple): The size of the structuring element (kernel) used for closing.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image after applying morphological closing.\n",
    "    \"\"\"\n",
    "    image=canny_image\n",
    "    for i in range(5):\n",
    "        # Create a structuring element (kernel) for closing\n",
    "        kernel = np.ones(kernel_size, np.uint8)\n",
    "        \n",
    "        # Apply morphological closing (dilation followed by erosion)\n",
    "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    closed_image = image\n",
    "    return closed_image\n",
    "def compute_features_for_contours(contours):\n",
    "    \"\"\"Compute morphological features for each contour.\"\"\"\n",
    "    all_features = []\n",
    "    for contour in contours:\n",
    "        features = compute_morphological_features(contour)\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "def remove_small_contours(image, min_area=80):\n",
    "    \"\"\"\n",
    "    Remove small contours from the image based on a minimum area threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): The input binary image (typically an edge-detected or thresholded image).\n",
    "    min_area (int): The minimum area threshold for keeping contours. Contours with area smaller than this will be removed.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image with small contours removed.\n",
    "    \"\"\"\n",
    "    # Find all contours in the image\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create an empty mask to draw the filtered contours\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    # Loop over each contour\n",
    "    for contour in contours:\n",
    "        # Calculate the contour area\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # If the contour area is larger than the minimum area, draw it on the mask\n",
    "        if area >= min_area:\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)  # Fill the contour\n",
    "    \n",
    "    return mask\n",
    "def draw_contours_on_image(image, contours):\n",
    "    \"\"\"\n",
    "    Draw contours on the original image and display them.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The original image or edge-detected image (e.g., Canny image).\n",
    "    contours (list): List of contours to draw on the image.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the image with contours using matplotlib.\n",
    "    \"\"\"\n",
    "    # Create a copy of the original image to draw on\n",
    "    image_with_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert grayscale image to BGR for colored contours\n",
    "    \n",
    "    # Draw the contours on the image (green color with thickness of 2)\n",
    "    cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the result using matplotlib\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(image_with_contours, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display in matplotlib\n",
    "    plt.title('Contours Overlayed on the Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def clean_image(canny_image):\n",
    "    # Step 1: Apply morphological closing with a kernel size of (1, 1)\n",
    "    closed_canny_image = apply_closing(canny_image, kernel_size=(3, 3))\n",
    "    # Step 2: Remove small contours based on area\n",
    "    cleaned_canny_image = remove_small_contours(closed_canny_image, min_area=80)\n",
    "    return cleaned_canny_image\n",
    "def compute_mean_and_std_for_all_crops(all_features):\n",
    "    \"\"\"Compute the mean and std for each feature (f1 to f6) across all crops.\"\"\"\n",
    "    features_array = {f'f{i}': [] for i in range(1, 7)}\n",
    "    \n",
    "    for features in all_features:\n",
    "        for key in features_array.keys():\n",
    "            features_array[key].append(features[key])\n",
    "\n",
    "    mean_features = {key: np.nanmean(values) for key, values in features_array.items()}\n",
    "    std_features = {key: np.nanstd(values) for key, values in features_array.items()}\n",
    "\n",
    "    return mean_features, std_features\n",
    "def save_mean_std_to_csv(species, mean_features, std_features, file_path='Morphological_all.csv'):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Species', 'Mean_f1', 'Mean_f2', 'Mean_f3', 'Mean_f4', 'Mean_f5', 'Mean_f6',\n",
    "                             'Std_f1', 'Std_f2', 'Std_f3', 'Std_f4', 'Std_f5', 'Std_f6'])\n",
    "        \n",
    "        mean_row = [mean_features[f'f{i}'] for i in range(1, 7)]\n",
    "        std_row = [std_features[f'f{i}'] for i in range(1, 7)]\n",
    "        \n",
    "        writer.writerow([species] + mean_row + std_row)\n",
    "        \n",
    "def is_closed_contour(contour, tolerance=3):\n",
    "    \"\"\"Check if the contour is 'closed' by comparing the start and end points.\"\"\"\n",
    "    start_point = contour[0]\n",
    "    end_point = contour[-1]\n",
    "    distance = np.linalg.norm(start_point - end_point)\n",
    "    return distance < tolerance\n",
    "Species=species+'_reconstruct'\n",
    "\n",
    "def get_reference_values(species_csv, species):\n",
    "    \"\"\"Get the reference mean and std values for f2 and f3 from the CSV.\"\"\"\n",
    "    with open(species_csv, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['Species'] == species:\n",
    "                mean_f2 = float(row['Mean_f2'])\n",
    "                std_f2 = float(row['Std_f2'])\n",
    "                mean_f3 = float(row['Mean_f3'])\n",
    "                std_f3 = float(row['Std_f3'])\n",
    "                return mean_f2, std_f2, mean_f3, std_f3\n",
    "    return None\n",
    "\n",
    "def is_within_valid_range(features, mean_f2, std_f2, mean_f3, std_f3):\n",
    "    \"\"\"Check if f2 and f3 of the current features are within valid ranges.\"\"\"\n",
    "    f2 = features['f2']\n",
    "    f3 = features['f3']\n",
    "    \n",
    "    valid_f2_range = [mean_f2 - 3*std_f2, mean_f2 + 3*std_f2]\n",
    "    valid_f3_range = [mean_f3 - 3*std_f3, mean_f3 + 3*std_f3]\n",
    "    \n",
    "    return (valid_f2_range[0] <= f2 <= valid_f2_range[1]) and (valid_f3_range[0] <= f3 <= valid_f3_range[1])\n",
    "\n",
    "\n",
    "# Example: Get reference values for species 'species_rgb'\n",
    "species_csv = 'Morphological_all.csv'\n",
    "species_ref = species+'_rgb'\n",
    "mean_f2_ref, std_f2_ref, mean_f3_ref, std_f3_ref = get_reference_values(species_csv, species_ref)\n",
    "\n",
    "# Apply Canny edge detection to RGB and HSI crops\n",
    "def Extract_rgb_bands(croped_reconstructed):\n",
    "    croped_reconstruct_rgb = [crops[:,:,rgb_bands] for crops in croped_reconstructed]\n",
    "    return croped_reconstruct_rgb   \n",
    "    \n",
    "croped_reconstruct_rgb= Extract_rgb_bands(croped_reconstruct)\n",
    "croped_reconstruct_rgb_uint8 = convert_list_to_uint8(croped_reconstruct_rgb)   \n",
    "canny_rgb_crops = apply_canny_to_crops(croped_reconstruct_rgb_uint8)\n",
    "valid_contour_features = []\n",
    "\n",
    "for i in range(48):\n",
    "    canny_image = clean_image(canny_rgb_crops[i])\n",
    "    \n",
    "    # Extract and filter contours\n",
    "    contours = extract_contours(canny_image)\n",
    "    closed_contours = [contour for contour in contours if is_closed_contour(contour)]\n",
    "    \n",
    "    if not closed_contours:\n",
    "        continue\n",
    "    \n",
    "    # Compute EFD and reconstruct shapes\n",
    "    efd_coeffs = compute_efd(closed_contours)\n",
    "    reconstructed_contours = [reconstruct_shape(coeffs, (200, 60)) for coeffs in efd_coeffs]\n",
    "    \n",
    "    # Compute contour features\n",
    "    contour_features = compute_features_for_contours(reconstructed_contours)\n",
    "    \n",
    "    # Check validity of the features (f2 and f3)\n",
    "    for features in contour_features:\n",
    "        if is_within_valid_range(features, mean_f2_ref, std_f2_ref, mean_f3_ref, std_f3_ref):\n",
    "            valid_contour_features.append(features)\n",
    "    \n",
    "    # Plot contours if valid\n",
    "    if valid_contour_features:\n",
    "        plot_contours(canny_image, contours, reconstructed_contours, valid_contour_features, i)\n",
    "    print(f\"Processed crop {i}\")\n",
    "\n",
    "# Compute mean and std for the valid features across all crops\n",
    "mean_features, std_features = compute_mean_and_std_for_all_crops(valid_contour_features)\n",
    "\n",
    "# Save the valid results to CSV\n",
    "save_mean_std_to_csv(Species, mean_features, std_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff03ed-4710-46e0-acfb-5f034d9c5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def compute_wavelength_profile(cropped_hsi, cropped_thresh):\n",
    "    \"\"\"Compute the mean intensity across spectral bands for each crop, excluding background.\"\"\"\n",
    "    wavelength_profiles = []\n",
    "    \n",
    "    # Loop over each cropped region\n",
    "    for crop_hsi, crop_thresh in zip(cropped_hsi, cropped_thresh):\n",
    "        mean_intensity_per_band = []\n",
    "        \n",
    "        # For each spectral band in the HSI image (assumed to be along axis 2)\n",
    "        num_bands = crop_hsi.shape[2]\n",
    "        for band in range(num_bands):\n",
    "            # Extract the band and corresponding threshold mask\n",
    "            band_image = crop_hsi[:, :, band]\n",
    "            thresh_mask = crop_thresh != 255  # Mask where the pixels are not background\n",
    "            \n",
    "            # Compute mean intensity of non-background pixels\n",
    "            mean_intensity = np.mean(band_image[thresh_mask])\n",
    "            mean_intensity_per_band.append(mean_intensity)\n",
    "        \n",
    "        # Store the intensity profile for the current crop\n",
    "        wavelength_profiles.append(mean_intensity_per_band)\n",
    "    \n",
    "    return wavelength_profiles\n",
    "\n",
    "def plot_wavelength_profiles(wavelength_profiles, num_crops):\n",
    "    \"\"\"Plot the wavelength profile for each cropped image.\"\"\"\n",
    "    for i, profile in enumerate(wavelength_profiles):\n",
    "        plt.plot(profile, label=f'Crop {i + 1}')\n",
    "    \n",
    "    plt.xlabel('Band Index')\n",
    "    plt.ylabel('Mean Intensity (Excluding Background)')\n",
    "    plt.title(f'Wavelength Profiles for {num_crops} Crops')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def save_mean_std_wavelength_profiles_to_csv(wavelength_profiles, species, file_name='wavprofile.csv'):\n",
    "    \"\"\"Compute and save the mean and std of the wavelength profiles across all crops to a CSV file.\"\"\"\n",
    "    # Convert the list of wavelength profiles to a NumPy array\n",
    "    wavelength_profiles = np.array(wavelength_profiles)\n",
    "    \n",
    "    # Compute mean and std across all crops for each band (axis 0 is the crop dimension)\n",
    "    mean_profile = np.mean(wavelength_profiles, axis=0)\n",
    "    std_profile = np.std(wavelength_profiles, axis=0)\n",
    "    \n",
    "    # Create a dictionary for the data to save with 160 columns (80 for mean, 80 for std)\n",
    "    data = {'Species': [species]}\n",
    "    \n",
    "    # Add mean and std columns for each band (Band_100 to Band_179)\n",
    "    for band in range(100, 180):\n",
    "        data[f'mean_{band}'] = [mean_profile[band]]\n",
    "        data[f'std_{band}'] = [std_profile[band]]\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    \n",
    "    if not file_exists:\n",
    "        # If file doesn't exist, create a header row with 'Species', 'mean_100', 'std_100', ..., 'mean_179', 'std_179'\n",
    "        columns = ['Species']\n",
    "        for band in range(100, 180):\n",
    "            columns.append(f'mean_{band}')\n",
    "            columns.append(f'std_{band}')\n",
    "        \n",
    "        # Create a DataFrame with just the column names and write to CSV\n",
    "        header_df = pd.DataFrame(columns=[columns])\n",
    "        header_df.to_csv(file_name, mode='w', index=False, header=True)\n",
    "    \n",
    "    # Save the DataFrame to CSV (append if file exists, otherwise create)\n",
    "    df.to_csv(file_name, mode='a', index=False, header=False) \n",
    "    \n",
    "Species=species+'_hsi'\n",
    "\n",
    "# Assuming `croped_hsi` is the cropped HSI images and `croped_thresh_hsi` is the corresponding thresholded images\n",
    "wavelength_profiles_hsi = compute_wavelength_profile(croped_hsi, croped_thresh_hsi)\n",
    "\n",
    "# Plot the wavelength profiles for the HSI crops (48 curves)\n",
    "plot_wavelength_profiles(wavelength_profiles_hsi, num_crops=len(wavelength_profiles_hsi))\n",
    "\n",
    "save_mean_std_wavelength_profiles_to_csv(wavelength_profiles_hsi, Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ccd87-fbfd-4462-8321-40ee4b6069f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Species=species+'_reconstruct'\n",
    "\n",
    "# Assuming `croped_hsi` is the cropped HSI images and `croped_thresh_hsi` is the corresponding thresholded images\n",
    "wavelength_profiles_hsi = compute_wavelength_profile(croped_reconstruct, croped_thresh_reconstruct)\n",
    "\n",
    "# Plot the wavelength profiles for the HSI crops (48 curves)\n",
    "plot_wavelength_profiles(wavelength_profiles_hsi, num_crops=len(wavelength_profiles_hsi))\n",
    "\n",
    "save_mean_std_wavelength_profiles_to_csv(wavelength_profiles_hsi, Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f82a06-134d-4e99-b4ab-f5dac3a29cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def compute_pixel_wavelength_profiles(cropped_hsi, cropped_thresh):\n",
    "    \"\"\"Compute the intensity values across spectral bands for each non-background pixel.\"\"\"\n",
    "    pixel_wavelength_profiles = []\n",
    "    \n",
    "    # Loop over each cropped region\n",
    "    for crop_hsi, crop_thresh in zip(cropped_hsi, cropped_thresh):\n",
    "        profiles_for_crop = []\n",
    "        \n",
    "        # Get non-background pixel positions (where the threshold mask is not 255)\n",
    "        non_background_indices = np.where(crop_thresh != 255)\n",
    "        \n",
    "        # For each non-background pixel, extract its intensity across all bands\n",
    "        for y, x in zip(*non_background_indices):\n",
    "            # Extract the pixel's intensity across all bands\n",
    "            pixel_profile = crop_hsi[y, x, :]  # This will be a vector of length equal to the number of bands\n",
    "            profiles_for_crop.append(pixel_profile)\n",
    "        \n",
    "        pixel_wavelength_profiles.append(profiles_for_crop)\n",
    "    \n",
    "    return pixel_wavelength_profiles\n",
    "\n",
    "def plot_pixel_wavelength_profiles(wavelength_profiles, crop_idx):\n",
    "    \"\"\"Plot wavelength profiles for each non-background pixel in a crop with mean and std.\"\"\"\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Get the number of profiles and create a color map\n",
    "    num_profiles = len(wavelength_profiles)\n",
    "    colors = cm.get_cmap('rainbow', num_profiles)  # Use the 'rainbow' colormap for distinct colors\n",
    "    \n",
    "    # Plot each pixel's wavelength profile with different colors\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, profile in enumerate(wavelength_profiles):\n",
    "        plt.plot(profile, color=colors(i), alpha=0.7)  # Assign different colors to each profile\n",
    "    \n",
    "    plt.xlabel('Band Index')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'Wavelength Profiles for Crop {crop_idx + 1}')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Convert wavelength_profiles to a numpy array for mean/std calculations\n",
    "    wavelength_profiles = np.array(wavelength_profiles)\n",
    "    \n",
    "    # Compute the mean and standard deviation across all pixels in the crop\n",
    "    mean_profile = np.mean(wavelength_profiles, axis=0)\n",
    "    std_profile = np.std(wavelength_profiles, axis=0)\n",
    "    \n",
    "    # Plot the mean and std in a separate subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(mean_profile, label='Mean', color='blue', linewidth=2)\n",
    "    plt.fill_between(range(len(mean_profile)), \n",
    "                     mean_profile - std_profile, \n",
    "                     mean_profile + std_profile, \n",
    "                     color='blue', alpha=0.3, label='Â± 1 Std. Dev.')\n",
    "    \n",
    "    plt.xlabel('Band Index')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'Mean and Std. Dev. for Crop {crop_idx + 1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compute pixel-wise wavelength profiles for all HSI cropped images\n",
    "pixel_wavelength_profiles_hsi = compute_pixel_wavelength_profiles(croped_hsi, croped_thresh_hsi)\n",
    "\n",
    "# Plot the wavelength profiles and mean/std for each crop\n",
    "for crop_idx, profiles in enumerate(pixel_wavelength_profiles_hsi):\n",
    "    plot_pixel_wavelength_profiles(profiles, crop_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
